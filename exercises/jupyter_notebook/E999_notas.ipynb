{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data, Science, Engineering and Machine Learning.\n","\n","\n","    \n","## Machine Learning\n","gradient descent, supervisionado> classificalçao e regrssçao. não super, associalçao, clusterizalçao,\n","redulçaod de dimensionalidade, quantização. semisupervi,. reforço. self-supervisionized\n","\n","\n","supervisionar é anotar, rotular, mas não precisa ser manualmente, pode-se importar um modelo pronto pra verificar teus dados.\n","\n","pra aprender é preciso acertar dados que tu nçao viu, solução desejada\n","sobre-ajuste: overfeeding, só memorizou\n","\n","supervisionado: mostrar 100 vezes que a imagem é cachorro\n","\n","regrassao linear é o basico de ML\n","\n","revisar o y^ do video de estatistica, aquilo diz sobre quão bom é utilizar uma regressão linear a partir do R**2 famoso ax + b, funçãozinha de ensino medio\n","\n","y é o output, tu quer fazer uma função que melhor estime a reta, de acordo com o menor r quadrado, o r quadrado é o erro, soma isso, quanto menor melhor, a reta que formar o melhor erro é a melhor, tu pode fazer uma média do erro, é ao quadrado pros erros nçao se anulare, uns vão ser negativos e outros mositivos, é bom colocar ao quadrado pra ajuda com derivadas parciais, também vom pra penalizar erros maiores (MNE Loss, minimum squared error, quão ruim é teu modelo)\n","\n","se tu tiver duas features, teu R2 vai ter que ser uma reta que acompanhe os dois dados, tendo o peso de dois gráficos em um modelo só, como o preço de uma casa de acordo com o tamanho e localização. duas regressões lineares que junto contribuem pra linha de preço, tradeoff de bias e variancia? ou bayes?\n","\n","gradiente descendente, gradiente é derivada\n","\n","\n","teoria da evolução que o animais nao conseguem evoluir pra um ponto que traria beneficio pra eles se eles forem passar por um ponto de desevolução, isso tiraria deles temporariamente a vantagem no meio, o resultado que a evolução quer alcançar. isso acontece da mesma forma se tu quiser descer um morro, tu tem o mesmo problema, tu quer o minimo global, não o pequeno vale local, isso faz uma função convexa ou não, como sair dos minimos locais? como dizer pro modelo que aquele minimo que ele achou não é a melhor saida ainda? ele precisa ter um entendimento sobre esse minimo e saber que ele tem que sair do local e que é válido ele gastar recursos pra subir esse morro temporariamente. nesse cenário, tu não pode ir pra uma derivada ao contrário do que tu tem que fazer\n","\n","\n","estudar python, pytorch - framework poderoso ( bom pra caluclar derivada, otimização)\n","sklearn é bom, com poucas linhas tu resolve bastante coisa"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN/viYiOGsRnbKiJjx5MFJM","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"01b8457f36e6ec2e803a14b94f23e8cb0d6894b2637528ba3547905af938f048"}}},"nbformat":4,"nbformat_minor":0}
